{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]]\n",
      "\n",
      "  [[2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]]\n",
      "\n",
      "  [[2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]\n",
      "   [2. 2. 2. 2.]]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.607 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:14<00:00, 37.25s/it]\n",
      "The following parameters in checkpoint files are not loaded:\n",
      "['model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq']\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = '/root/code/llama2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[è¿™é‡Œä¼šè·³ä¸€ä¸ªæ—‹è½¬ç¼–ç æœªåŠ è½½çš„ä¿¡æ¯ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œå“ˆå“ˆï¼Œæ€»ä¹‹æŸ¥äº†ä¸‹issueï¼Œä¸å¾®è°ƒå°±æ²¡äº‹,ä¹Ÿæœ‰è¯´æ˜¯æ¨¡åž‹åŠ è½½æ–¹å¼é—®é¢˜ï¼Œä¹Ÿæœ‰è¯´æ˜¯transformerç‰ˆæœ¬é—®é¢˜](https://github.com/LianjiaTech/BELLE/issues/349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '''<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "There's a llama in my garden ðŸ˜± What should I do? [/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\n\\nThere's a llama in my garden ðŸ˜± What should I do? [/INST]  Thank you for reaching out! I'm here to help you with your question. ðŸ˜Š\\n\\nFirstly, I must say that it's quite unexpected to have a llama in your garden! ðŸ˜‚ However, I understand that you might be curious or even concerned about how to handle this situation.\\n\\nBefore we proceed, I want to clarify that llamas are domesticated animals and are not typically found in residential areas. It's possible that the llama might have wandered into your garden accidentally or might be lost.\\n\\nIf you are comfortable with the llama being in your garden, you could try contacting a local animal rescue organization or a veterinarian for assistance. They can help you locate the llama's owner and ensure its safety.\\n\\nIf you are not comfortable with the llama being in your garden, you could try contacting the local animal control agency for assistance. They can help you safely capture the llama and take it to a nearby shelter or sanctuary.\\n\\nIn any case, please make sure to approach the llama with caution and respect. Llamas are large animals and can be unpredictable if they feel threatened\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "gen_config = model.generation_config\n",
    "gen_config.max_new_tokens = 256\n",
    "toks = tokenizer(input).input_ids\n",
    "input_ids = ms.tensor(toks)\n",
    "input_ids = input_ids.unsqueeze(0)\n",
    "attn_masks = ms.ops.ones_like(input_ids)\n",
    "output_ids = model.generate(input_ids, \n",
    "    attention_mask=attn_masks, \n",
    "    generation_config=gen_config,\n",
    "    pad_token_id=tokenizer.pad_token_id)[0]\n",
    "output = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
